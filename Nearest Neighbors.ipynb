{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import average_precision_score\n",
    "import numpy as np\n",
    "import numexpr as ne\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\", index_col=\"row_id\").values\n",
    "\n",
    "X_train = train[:,0:4]\n",
    "y_train = train[:,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "limit = 4000\n",
    "\n",
    "permutation = np.random.permutation(len(X_train))\n",
    "test_indicies = permutation[slice(0,min(limit,len(X_train)))]\n",
    "\n",
    "X_test = train[test_indicies, 0:4]\n",
    "y_test = train[test_indicies, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "day = 1440\n",
    "hour = 60\n",
    "week = 10080\n",
    "\n",
    "def np_hash(a1, a2=None):\n",
    "    if a1 is None or a2 is None:\n",
    "        return None\n",
    "    return hash(str(a1)+str(a1.shape)+str(a1.size)+str(a2)+str(a2.shape)+str(a2.size))\n",
    "\n",
    "class FacebookCheckins(BaseEstimator, ClassifierMixin):\n",
    "    \n",
    "    X = None\n",
    "    place_id = None\n",
    "    cache = {}\n",
    "    \n",
    "    def __init__(self, X, place_id, kNN=400, a_scale=1, a_min=1, a_bias=0, time_model='proximity',\n",
    "                 day_w1=0, day_w2=12*hour, day_mp=0,\n",
    "                 week_w1=0, week_w2=3.5*day, week_mp=0,\n",
    "                 time_w1=20*week, time_w2=50*week, time_mp=1):\n",
    "        keys = self.cache.keys()\n",
    "        if 'Xy' in keys and self.cache['Xy'] != np_hash(X, place_id):\n",
    "            if 'NN' in keys:\n",
    "                del self.cache['NN']\n",
    "            if 'neighbors' in keys:\n",
    "                del self.cache['neighbors']\n",
    "        if 'kNN' in keys and self.cache['kNN'] != kNN and 'neighbors' in keys:\n",
    "            del self.cache['neighbors']\n",
    "            \n",
    "        self.cache['Xy'] = np_hash(X, place_id)\n",
    "        \n",
    "        self.X = X\n",
    "        self.x = X[:,0] # kilometers\n",
    "        self.y = X[:,1] # kilometers\n",
    "        self.accuracy = X[:,2] * 0.001 # convert meters to kilometers\n",
    "        self.time = X[:,3] # units are minutes\n",
    "        self.time_of_day = X[:,3] % 1440 # minutes\n",
    "        self.time_of_week = X[:,3] % 10080 # minutes\n",
    "        self.place_id = place_id\n",
    "        self.kNN = kNN\n",
    "        self.a_scale = a_scale\n",
    "        self.a_min = a_min\n",
    "        self.a_bias = a_bias\n",
    "        self.time_model = time_model\n",
    "        self.day_w1 = day_w1\n",
    "        self.day_w2 = day_w2\n",
    "        self.day_mp = day_mp\n",
    "        self.week_w1 = week_w1\n",
    "        self.week_w2 = week_w2\n",
    "        self.week_mp = week_mp\n",
    "        self.time_w1 = time_w1\n",
    "        self.time_w2 = time_w2\n",
    "        self.time_mp = time_mp\n",
    "        \n",
    "        self.X_test = None\n",
    "        self.y_test = None\n",
    "        \n",
    "    def time_difference(self, time1, time2, period=None):\n",
    "        \"\"\"Find the different in time even if measure is periodic.\"\"\"\n",
    "        if period:\n",
    "            hp = 0.5 * period\n",
    "            return ne.evaluate('hp-abs(abs(time1-time2) - hp)')\n",
    "        else:\n",
    "            return ne.evaluate('abs(time1-time2)')\n",
    "\n",
    "    def prob_overlap_time(self, diff, w1, w2, mp):\n",
    "        \"\"\"Compute the probability the the time difference is significant.\"\"\"\n",
    "        # derive equation of line that connects end of w1 and w2\n",
    "        # points: (w1, 1), (w2, mp)\n",
    "        # dy = mp-1, dx = w2-w1, m = (mp-1)/(w2-w1)\n",
    "        # y = m * x + b\n",
    "        # substitude in point 1\n",
    "        # 1 = (mp-1)/(w2-w1) * w1 + b\n",
    "        # solve for b\n",
    "        # b = 1 - (mp-1)/(w2-w1) * w1\n",
    "        # y = (mp-1)/(w2-w1) * x + 1 - (mp-1)/(w2-w1)\n",
    "        prob = ne.evaluate('(mp-1)/(w2-w1) * diff + 1 - (mp-1)/(w2-w1) * w1')\n",
    "        prob = np.where(diff < w1, 1, prob)\n",
    "        return np.where(diff > w2, mp, prob)\n",
    "\n",
    "    def prob_overlap_locations(self, x1, y1, x2, y2, accuracy1, accuracy2):\n",
    "        \"\"\"Compute the probability that location measurements represent the same point.\"\"\"\n",
    "        return ne.evaluate('exp(-0.5 * ((x1-x2)**2+(y1-y2)**2) / (accuracy1 ** 2 + accuracy2 ** 2)) / \\\n",
    "                            (accuracy1 ** 2 + accuracy2 ** 2)') # / (2 * np.pi)\n",
    "\n",
    "    def sum_by_group(self, values, groups):\n",
    "        \"\"\"Sum a list of values by groups.\"\"\"\n",
    "        order = np.argsort(groups)\n",
    "        groups = groups[order]\n",
    "        values = values[order]\n",
    "        values.cumsum(out=values)\n",
    "        index = np.ones(len(groups), 'bool')\n",
    "        index[:-1] = groups[1:] != groups[:-1]\n",
    "        values = values[index]\n",
    "        groups = groups[index]\n",
    "        values[1:] = values[1:] - values[:-1]\n",
    "        return values, groups\n",
    "\n",
    "\n",
    "    def predict_internal(self, X, neighbors, self_validation=False):\n",
    "\n",
    "        x_test = X[:,0].reshape((-1,1)) # units are kilometers\n",
    "        y_test = X[:,1].reshape((-1,1)) # units are kilometers\n",
    "        a_test = X[:,2].reshape((-1,1)) * 0.001\n",
    "        time_test = X[:,3].reshape((-1,1))\n",
    "        day_test = X[:,3].reshape((-1,1)) % 1440\n",
    "        week_test = X[:,3].reshape((-1,1)) % 10080\n",
    "\n",
    "        def scale_accuracy(accuracy):\n",
    "            scale = self.a_scale\n",
    "            bias = self.a_bias\n",
    "            a_min = self.a_min\n",
    "            return np.maximum(accuracy + bias, a_min) * scale\n",
    "\n",
    "        neighbor_accuracies = scale_accuracy(self.accuracy[neighbors])\n",
    "        test_accuracy = scale_accuracy(a_test)\n",
    "        colocation_prob = self.prob_overlap_locations(x_test, y_test, self.x[neighbors], self.y[neighbors],\n",
    "                                                      test_accuracy, neighbor_accuracies)\n",
    "\n",
    "        time_of_day_diff = self.time_difference(day_test, self.time_of_day[neighbors], day)\n",
    "        time_of_day_prob = self.prob_overlap_time(time_of_day_diff, self.day_w1, self.day_w2, self.day_mp)\n",
    "\n",
    "        time_of_week_diff = self.time_difference(week_test, self.time_of_week[neighbors], week)\n",
    "        time_of_week_prob = self.prob_overlap_time(time_of_week_diff, self.week_w1, self.week_w2, self.week_mp)\n",
    "\n",
    "        time_diff = self.time_difference(time_test, self.time[neighbors])\n",
    "        time_prob = self.prob_overlap_time(time_diff, self.time_w1, self.time_w2, self.time_mp)\n",
    "\n",
    "        total_prob = ne.evaluate('colocation_prob * time_of_day_prob * time_of_week_prob * time_prob')\n",
    "\n",
    "        s = slice(1,None) if self_validation else slice(0,None) # skip the first neighbor if self validating\n",
    "        self.predictions = np.zeros((len(X),3))\n",
    "        for i, (prob, places) in enumerate(zip(total_prob[:,s], self.place_id[neighbors][:,s])):\n",
    "            # append a few zeros just incase there is only one nearby place\n",
    "            # we need three for the precision calculation\n",
    "            prob, places = self.sum_by_group(np.append(prob, [0,0]), np.append(places, [0,1]))\n",
    "            prob, places = zip(*sorted(zip(prob, places),reverse=True))\n",
    "            self.predictions[i,:] = places[:3]\n",
    "        return self.predictions\n",
    "\n",
    "    def mean_average_precision3(self, true, test):\n",
    "        precision = np.array([1, 1/2, 1/3])\n",
    "        return ne.evaluate('sum((true == test) * precision)') / len(true)\n",
    "    \n",
    "    def fit(self, X_test, y_test):\n",
    "        keys = self.cache.keys()\n",
    "        if 'NN' not in keys:\n",
    "            print(\"Setup NearestNeighbors and fit\")\n",
    "            self.cache['NN'] = NearestNeighbors(n_jobs=-1, algorithm='kd_tree').fit(self.X[:,0:2], self.place_id)\n",
    "        if 'Xy_test' in keys and self.cache['Xy_test'] != np_hash(X_test, y_test):\n",
    "            if 'neighbors' in keys:\n",
    "                del self.cache['neighbors']\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "        self.cache['Xy_test'] = np_hash(X_test, y_test)\n",
    "        \n",
    "        if 'neighbors' not in keys:\n",
    "            print(\"Find nearest neighbors to test points\")\n",
    "            self.cache['kNN'] = self.kNN\n",
    "            self.cache['neighbors'] = self.cache['NN'].kneighbors(X_test[:,0:2], n_neighbors=self.kNN,\n",
    "                                                   return_distance=False).astype(np.int32)\n",
    "        print(\"predict\")\n",
    "        self.predictions = self.predict_internal(X_test, self.cache['neighbors'], self_validation=True)\n",
    "        \n",
    "        return self    \n",
    "    \n",
    "    def predict(self, X):\n",
    "        self.predict_internal(self.X_test, self.neighbors, self_validation=False)\n",
    "        return self.predictions\n",
    "    \n",
    "    def score(self, X=None, y=None, sample_weight=None):\n",
    "        print(\"score\")\n",
    "        return self.mean_average_precision3(self.y_test.reshape((-1,1)), self.predictions)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup NearestNeighbors and fit\n",
      "Find nearest neighbors to test points\n",
      "predict\n",
      "score\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0032916666666666671"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parameters\n",
    "parameters = { 'kNN': 400, \n",
    "               'a_scale': 1,\n",
    "               'a_min': 1,\n",
    "               'a_bias': 0,\n",
    "               'time_model': 'proximity', # or 'histogram'\n",
    "               'day_w1': 0,\n",
    "               'day_w2': 12*hour,\n",
    "               'day_mp': 0,\n",
    "               'week_w1': 0,\n",
    "               'week_w2': 3.5*day,\n",
    "               'week_mp': 0,\n",
    "               'time_w1': 20*week,\n",
    "               'time_w2': 50*week,\n",
    "               'time_mp': 1\n",
    "             }\n",
    "del clf\n",
    "clf = FacebookCheckins(X=X_train[:10000], place_id=y_train)\n",
    "clf.fit(X_test, y_test)\n",
    "clf.score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict\n",
      "score\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0032916666666666671"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_test, y_test)\n",
    "clf.score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup NearestNeighbors and fit\n",
      "Find nearest neighbors to test points\n",
      "predict\n",
      "score\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0032916666666666671"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2 = FacebookCheckins(X=X_train[:1000], place_id=y_train, kNN=200)\n",
    "clf2.fit(X_test, y_test)\n",
    "clf.score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shawn/miniconda3/lib/python3.5/site-packages/sklearn/cross_validation.py:516: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=3.\n",
      "  % (min_labels, self.n_folds)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup NearestNeighbors and fit\n",
      "Find nearest neighbors to test points\n",
      "predict\n",
      "score\n",
      "Find nearest neighbors to test points\n",
      "predict\n",
      "score\n",
      "Find nearest neighbors to test points\n",
      "predict\n",
      "score\n",
      "Find nearest neighbors to test points\n",
      "predict\n",
      "score\n",
      "Find nearest neighbors to test points\n",
      "predict\n",
      "score\n",
      "Find nearest neighbors to test points\n",
      "predict\n",
      "score\n",
      "Find nearest neighbors to test points\n",
      "predict\n",
      "score\n",
      "Find nearest neighbors to test points\n",
      "predict\n",
      "score\n",
      "Find nearest neighbors to test points\n",
      "predict\n",
      "score\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=FacebookCheckins(X=array([[  7.94100e-01,   9.08090e+00,   5.40000e+01,   4.70702e+05],\n",
       "       [  5.95670e+00,   4.79680e+00,   1.30000e+01,   1.86555e+05],\n",
       "       ...,\n",
       "       [  8.99410e+00,   8.86860e+00,   1.60000e+01,   4.67366e+05],\n",
       "       [  4.27000e-02,   4.02640e+00,   1.66000e+02,...roximity', time_mp=1, time_w1=201600, time_w2=504000,\n",
       "         week_mp=0, week_w1=0, week_w2=5040.0),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'a_scale': [0.9, 1, 1.1]}, pre_dispatch='2*n_jobs',\n",
       "       refit=False, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import grid_search\n",
    "\n",
    "clf = FacebookCheckins(X=X_train[:10000], place_id=y_train[:10000])\n",
    "search = grid_search.GridSearchCV(clf, { 'a_scale': [0.9, 1, 1.1]}, refit=False)\n",
    "search.fit(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
